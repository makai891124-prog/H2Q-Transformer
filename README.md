# ğŸŒŒ H2Q-MicroStream: Holographic Hamiltonian Quaternion Transformer

> **"æ™ºèƒ½ä¸æ˜¯è®°å¿†è¿‡å»çš„æ‰€æœ‰ç»†èŠ‚ï¼Œè€Œæ˜¯æŒæ¡ç”Ÿæˆæœªæ¥çš„æ ¸å¿ƒæ–¹ç¨‹ã€‚"**
>
> **"Intelligence is not about memorizing every detail of the past, but mastering the core equations that generate the future."**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange)](https://pytorch.org/)
[![Status](https://img.shields.io/badge/Status-Experimental-blueviolet)](https://github.com/)

---

## ğŸ“– é¡¹ç›®ç®€ä»‹ / Introduction

**H2Q-MicroStream** æ˜¯ä¸€ä¸ªæå…·å®éªŒæ€§çš„æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œæ—¨åœ¨æ¢ç´¢**è¯­è¨€æ¨¡å‹çš„ç‰©ç†åŠ¨åŠ›å­¦æœ¬è´¨**ã€‚ä¸è¿½æ±‚å·¨å¤§å‚æ•°é‡å’Œè¶…é•¿ä¸Šä¸‹æ–‡çª—å£çš„ä¸»æµ Transformer ä¸åŒï¼Œæœ¬é¡¹ç›®åŸºäº**å¥¥å¡å§†å‰ƒåˆ€åŸåˆ™ (Occam's Razor)** å’Œ **å…¨æ¯åŸç† (Holographic Principle)**ï¼Œæ„å»ºäº†ä¸€ä¸ªæç®€ã€å®æ—¶ã€ä¸”å…·æœ‰å¼ºç‰©ç†çº¦æŸçš„â€œæ€ç»´å†…æ ¸â€ã€‚

**H2Q-MicroStream** is a highly experimental deep learning architecture designed to explore the **physical dynamics of language models**. Unlike mainstream Transformers that chase massive parameter counts and infinite context windows, this project builds a minimalist, real-time, and physically constrained "Thinking Kernel" based on **Occam's Razor** and the **Holographic Principle**.

### æ ¸å¿ƒå“²å­¦ / Core Philosophy

1.  **æ€è€ƒå†…åŒ– vs. è¯­è¨€è¡¨è¾¾ (Internalization vs. Expression)**:
    *   æˆ‘ä»¬è®¤ä¸ºï¼Œç°æœ‰çš„ LLM èŠ±è´¹äº†å¤ªå¤šç®—åŠ›å»å­¦ä¹ â€œå¦‚ä½•åƒäººä¸€æ ·è¯´è¯â€ï¼ˆè¯­æ³•ç³–ï¼‰ï¼Œè€Œå¿½ç•¥äº†â€œå¦‚ä½•æ„å»ºä¸–ç•Œæ¨¡å‹â€ï¼ˆæ ¸å¿ƒé€»è¾‘ï¼‰ã€‚
    *   H2Q æ—¨åœ¨æ„å»ºä¸€ä¸ª**é«˜ç»´å…¨å‘çš„æ€ç»´æ ¸å¿ƒ**ã€‚å®ƒçš„ä¸­é—´çŠ¶æ€å¯èƒ½äººç±»éš¾ä»¥ç›´æ¥ç†è§£ï¼ˆç±»ä¼¼äºè„‘ç”µæ³¢ï¼‰ï¼Œä½†å®ƒåŒ…å«äº†å¯¹ä¿¡æ¯æœ¬è´¨çš„æ‹“æ‰‘æ˜ å°„ã€‚
    *   *We believe current LLMs spend too much compute on "speaking like a human" (syntax) rather than "modeling the world" (core logic). H2Q aims to build a high-dimensional, omnidirectional thinking kernel.*

2.  **çŠ¶æ€ä¿æŒ vs. å†å²å›æº¯ (State-based vs. Retrieval-based)**:
    *   äººç±»æ²¡æœ‰ 128k çš„ä¸Šä¸‹æ–‡çª—å£ã€‚æˆ‘ä»¬é çš„æ˜¯**æ ¸å¿ƒçŠ¶æ€ (State)** çš„å®æ—¶æ¼”åŒ–ã€‚
    *   æœ¬æ¶æ„æ”¾å¼ƒäº†å¯¹å†å²æ•°æ®çš„æ— é™ Attentionï¼Œè½¬è€Œè¿½æ±‚åœ¨æçŸ­è§†ç•Œï¼ˆMicro-Horizonï¼‰å†…çš„**å“ˆå¯†é¡¿åŠ¨åŠ›å­¦æ¼”åŒ–**ã€‚
    *   *Humans don't utilize 128k context windows; we rely on the real-time evolution of a Core State. This architecture abandons infinite attention on history in favor of Hamiltonian dynamic evolution within a Micro-Horizon.*

3.  **æœ¬è´¨å‹ç¼© (Essence Compression)**:
    *   å¦‚æœä¸€ä¸ªè§„å¾‹ä¸èƒ½ç”¨æå°‘çš„åŸºåº•ï¼ˆRank 8ï¼‰è§£é‡Šï¼Œé‚£å°±æ˜¯åœ¨æ­»è®°ç¡¬èƒŒã€‚
    *   *If a pattern cannot be explained with a minimal basis (Rank 8), it is rote memorization, not learning.*

---

## ğŸš€ å…³é”®æŠ€æœ¯ç‰¹æ€§ / Key Technical Features

### 1. ğŸŒŒ å››å…ƒæ•°æ—¶ç©ºæ³¨æ„åŠ› (Quaternion Spacetime Attention)
å¼•å…¥**å››å…ƒæ•° (Quaternion)** ä»£æ•°ï¼Œå°†æ³¨æ„åŠ›æœºåˆ¶ä»æ ‡é‡ç§¯å‡çº§ä¸º**å››ç»´æ—¶ç©ºå¹²æ¶‰**ã€‚
*   **å®éƒ¨ (Real Part)**: ä»£è¡¨èƒ½é‡/å¹…åº¦ï¼Œå†³å®šæ³¨æ„åŠ›çš„å¼ºåº¦ã€‚
*   **è™šéƒ¨ (Imaginary Part)**: ä»£è¡¨è‡ªæ—‹/ç›¸ä½ï¼Œå¼•å…¥éçº¿æ€§çš„**ç›¸ä½æ—‹è½¬åé¦ˆ (Phase Rotation)**ã€‚
*   è¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ•æ‰è¯­è¨€ä¸­çš„â€œçº ç¼ â€å’Œâ€œåè®½â€ç­‰é«˜ç»´ç‰¹å¾ã€‚

*Moves attention from scalar products to **4D spacetime interference**. Real parts represent energy/amplitude; Imaginary parts represent spin/phase, introducing nonlinear Phase Rotation Feedback to capture high-dimensional linguistic entanglement.*

### 2. ğŸ“‰ Rank-8 æœ¬è´¨çº¦æŸ (Rank-8 Essential Constraint)
æ¨¡å‹æƒé‡ä¸æ˜¯é™æ€çŸ©é˜µï¼Œè€Œæ˜¯é€šè¿‡ **Structure Bank** åŠ¨æ€ç”Ÿæˆçš„ã€‚æˆ‘ä»¬å¼ºåˆ¶å°† Rank é™åˆ¶ä¸º **8**ã€‚
*   è¿™é€¼è¿«æ¨¡å‹æ”¾å¼ƒâ€œèƒŒä¹¦â€ï¼Œåªèƒ½æå–æœ€æ ¸å¿ƒçš„ 8 ç§æ—¶ç©ºæ¼”åŒ–è§„å¾‹ã€‚
*   è¿™ä¹Ÿæå¤§åœ°é™ä½äº†è®¡ç®—æ¶ˆè€—ï¼Œå®ç°äº†å‚æ•°çš„â€œå…¨æ¯æŠ˜å â€ã€‚

*Weights are dynamically generated via a Structure Bank with a forced **Rank of 8**. This forces the model to abandon rote memorization and extract only the 8 most essential spacetime evolution patterns.*

### 3. ğŸŒŠ Unicode æµå¼åŠ¨åŠ›å­¦ (Unicode Stream Dynamics)
æ‘’å¼ƒäº† BPE Tokenizerï¼ˆå¦‚ Tiktokenï¼‰ï¼Œç›´æ¥ä½¿ç”¨ **Unicode (ASCII/UTF-8)** ç¼–ç ã€‚
*   **æ‹’ç»â€œæ–¹è¨€â€**ï¼šå»ºç«‹é€šç”¨çš„åº•å±‚ç‰©ç†æ¥å£ï¼Œè®©æ¨¡å‹ç›´æ¥å¤„ç†å­—èŠ‚æµã€‚
*   **å¹¶è¡Œæµè®­ç»ƒ**ï¼šæ¨¡æ‹Ÿå¤šè·¯å¹¶è¡Œçš„è¿ç»­é˜…è¯»ä½“éªŒï¼Œè€Œééšæœºåˆ‡ç‰‡ã€‚

*Abandons BPE Tokenizers for direct **Unicode (ASCII/UTF-8)** encoding. establishing a universal physical interface. Uses parallel streaming to simulate continuous reading flow rather than random slicing.*

### 4. âš¡ï¸ å¾®æ‰¹æ¬¡é«˜é¢‘æ›´æ–° (Micro-Batch High-Freq Update)
*   **Batch Size = 24**: æ¨¡æ‹Ÿæä½å®¹é‡çš„çŸ­æœŸè®°å¿†ã€‚
*   **No Gradient Accumulation**: æ¯çœ‹ä¸€çœ¼æ•°æ®å°±æ›´æ–°ä¸€æ¬¡å‚æ•°ã€‚
*   è¿™æ¨¡æ‹Ÿäº†ç”Ÿç‰©ç¥ç»å…ƒçš„**é«˜é¢‘è„‰å†²å­¦ä¹ **ï¼Œä½¿å‚æ•°åœ¨æµå½¢ç©ºé—´ä¸­è¿›è¡Œè¿ç»­çš„å¾®åˆ†æ¼”åŒ–ã€‚

*Simulates biological high-frequency impulse learning. With a micro-batch of 24 and continuous updates, the parameters undergo continuous differential evolution in the manifold space.*

---

## ğŸ› ï¸ å®‰è£…ä¸è¿è¡Œ / Installation & Usage

### ç¯å¢ƒè¦æ±‚ / Requirements
*   Python 3.8+
*   PyTorch 2.0+ (CUDA support recommended for TF32 acceleration)
*   NVIDIA GPU (Optimized for Ampere/Ada architectures like RTX 3090/4090/4070Ti)

### å¿«é€Ÿå¼€å§‹ / Quick Start

1.  **å…‹éš†ä»“åº“ / Clone the repository**
    ```bash
    git clone https://github.com/makai891124-prog/H2Q-Transformer.git
    cd H2Q-Transformer
    ```

2.  **å®‰è£…ä¾èµ– / Install dependencies**
    ```bash
    pip install torch numpy requests
    ```

3.  **è¿è¡Œè®­ç»ƒ / Run training**
    æ— éœ€æ‰‹åŠ¨ä¸‹è½½æ•°æ®ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨ä¸‹è½½ WikiText-2 æ•°æ®é›†å¹¶å¼€å§‹è®­ç»ƒã€‚
    *No need to manually download data; the script will automatically download WikiText-2 and start training.*
    ```bash
    python main.py
    ```

---

## ğŸ“Š é…ç½®è¯´æ˜ / Configuration

åœ¨ `main.py` ä¸­çš„ `CONFIG` å­—å…¸ä¸­è°ƒæ•´å‚æ•°ã€‚å½“å‰é»˜è®¤é…ç½®ä¸º **"H2Q-MicroStream"** æ¨¡å¼ï¼š

```python
CONFIG = {
    'dim': 768,            # æ¨¡å‹å®½åº¦ (GPT-2 Small level)
    'fixed_rank': 8,       # ğŸŒŸ æ ¸å¿ƒå‚æ•°ï¼šé™åˆ¶æ¨¡å‹çš„"è„‘å®¹é‡"ä»¥é€¼è¿«å…¶æ€è€ƒ
    'seq_len': 128,        # å¾®è§†ç•Œï¼šåªå…³æ³¨å½“ä¸‹ç¬é—´
    'batch_size': 24,      # ç‰©ç† Batchï¼šæå°ï¼Œé«˜é¢‘æ›´æ–°
    'depth': 12,           # æ·±åº¦
    'axiom_lambda': 0.1,   # æ­£äº¤æ€§çº¦æŸå¼ºåº¦
    # ...
}
```

---

## ğŸ”® å±•æœ›ä¸æœªæ¥ / Future Roadmap

ç›®å‰çš„ H2Q æ¨¡å‹æ˜¯ä¸€ä¸ª**çº¯ç²¹çš„æ€ç»´å†…æ ¸**ã€‚å®ƒçš„è¾“å‡ºå¯èƒ½çœ‹èµ·æ¥åƒâ€œä¹±ç â€æˆ–æå…¶æŠ½è±¡çš„æ–¹è¨€ï¼Œè¿™æ˜¯å› ä¸ºå®ƒæ­£åœ¨å±•ç¤ºå†…éƒ¨çš„**åŸå§‹çŠ¶æ€æµ**ã€‚

æœªæ¥çš„å¼€å‘è®¡åˆ’åŒ…æ‹¬ï¼š
1.  **è§£ç å™¨æŒ‚è½½ (Projector)**: è®­ç»ƒä¸€ä¸ªç‹¬ç«‹çš„â€œç¿»è¯‘å™¨â€æ¨¡å—ï¼Œå°† H2Q çš„å…¨æ¯çŠ¶æ€æ˜ å°„å›äººç±»è‡ªç„¶è¯­è¨€ã€‚
2.  **å¤šæ¨¡æ€æµ (Multimodal Stream)**: ç”±äºé‡‡ç”¨ Unicode/Byte æ¥å£ï¼Œå°è¯•ç›´æ¥è¾“å…¥éŸ³é¢‘æˆ–å›¾åƒå­—èŠ‚æµã€‚
3.  **è¾¹ç¼˜ä¾§éƒ¨ç½² (Edge Deployment)**: åˆ©ç”¨ Rank-8 çš„æé«˜å‹ç¼©ç‡ï¼Œå°è¯•åœ¨ç§»åŠ¨ç«¯è¿è¡Œå…¨æ¯å†…æ ¸ã€‚

*The current H2Q model is a **pure thinking kernel**. Future plans include training a separate "Projector" to translate holographic states into human language, exploring multimodal byte streams, and edge deployment via high compression rates.*

---

## ğŸ“œ è®¸å¯è¯ / License

æœ¬é¡¹ç›®é‡‡ç”¨ [MIT License](LICENSE) å¼€æºã€‚

---

### è‡´è°¢ / Acknowledgements
æ„Ÿè°¢æ‰€æœ‰æ¢ç´¢å‡ ä½•æ·±åº¦å­¦ä¹ ã€SSM (State Space Models) ä»¥åŠå¯¹ Transformer æ¶æ„è¿›è¡Œåæ€çš„ç ”ç©¶è€…ä»¬ã€‚æœ¬é¡¹ç›®çš„çµæ„Ÿæ¥æºäºå…¨æ¯åŸç†ã€å“ˆå¯†é¡¿åŠ›å­¦ä»¥åŠäººç±»è®¤çŸ¥çš„æœ¬è´¨ã€‚
